{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af3bd6e1-cbbf-4459-86a6-f943bdd2739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Data...\n",
      "Fetched 50000 rows, total: 50000\n",
      "Fetched 50000 rows, total: 100000\n",
      "Fetched 50000 rows, total: 150000\n",
      "Fetched 50000 rows, total: 200000\n",
      "Fetched 50000 rows, total: 250000\n",
      "Fetched 50000 rows, total: 300000\n",
      "Fetched 50000 rows, total: 350000\n",
      "Fetched 50000 rows, total: 400000\n",
      "Fetched 50000 rows, total: 450000\n",
      "Fetched 50000 rows, total: 500000\n",
      "Fetched 50000 rows, total: 550000\n",
      "Fetched 50000 rows, total: 600000\n",
      "Fetched 50000 rows, total: 650000\n",
      "Fetched 50000 rows, total: 700000\n",
      "Fetched 50000 rows, total: 750000\n",
      "Fetched 50000 rows, total: 800000\n",
      "Fetched 50000 rows, total: 850000\n",
      "Fetched 50000 rows, total: 900000\n",
      "Fetched 50000 rows, total: 950000\n",
      "Fetched 50000 rows, total: 1000000\n",
      "Fetched 4991 rows, total: 1004991\n",
      "Dropped column 'cross_street' (>80% missing).\n",
      "Dropped column 'crm_cd_2' (>80% missing).\n",
      "Dropped column 'crm_cd_3' (>80% missing).\n",
      "Dropped column 'crm_cd_4' (>80% missing).\n",
      "DataFrame exported to: C:\\Users\\I don't know\\Crime_Data_in_Los_Angeles_2020_to_Present\\data\\processed\\cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "data_cleaning.py\n",
    "----------------\n",
    "Module for fetching and cleaning Los Angeles crime data from the public API.\n",
    "\n",
    "Steps:\n",
    "1. Fetch raw data from LA city API in batches.\n",
    "2. Clean and standardize string columns.\n",
    "3. Drop columns with too many missing values (> 80%).\n",
    "4. Normalize victim demographics (sex, descent).\n",
    "5. Clean and validate date and time fields.\n",
    "6. Save the cleaned dataset to CSV.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "# =========================\n",
    "# API Settings\n",
    "# =========================\n",
    "BASE_URL = \"https://data.lacity.org/resource/2nrs-mtv8.json\"\n",
    "LIMIT = 50000  # max rows per API call\n",
    "\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"\n",
    "    Fetches all rows from the LA crime API in batches.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Raw DataFrame of all crime records.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    all_data = []\n",
    "    print(\"Fetching Data...\")\n",
    "\n",
    "    while True:\n",
    "        url = f\"{BASE_URL}?$limit={LIMIT}&$offset={offset}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        batch = response.json()\n",
    "        if not batch:  # Stop when no more rows\n",
    "            break\n",
    "\n",
    "        all_data.extend(batch)\n",
    "        offset += LIMIT\n",
    "        print(f\"Fetched {len(batch)} rows, total: {len(all_data)}\")\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_spaces(val):\n",
    "    \"\"\"Removes extra spaces from string values.\"\"\"\n",
    "    if isinstance(val, str):\n",
    "        return \" \".join(val.split())\n",
    "    return val\n",
    "\n",
    "\n",
    "def nan_percentage_and_drop(df, column_name, threshold=80):\n",
    "    \"\"\"\n",
    "    Drops a column if missing values exceed the threshold.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to process.\n",
    "        column_name (str): Column name.\n",
    "        threshold (float): Percentage threshold for dropping.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Modified DataFrame.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        return df\n",
    "\n",
    "    total_rows = len(df)\n",
    "    missing_count = df[column_name].isna().sum()\n",
    "    percent_missing = (missing_count / total_rows) * 100\n",
    "\n",
    "    if percent_missing > threshold:\n",
    "        df = df.drop(columns=[column_name])\n",
    "        print(f\"Dropped column '{column_name}' (>{threshold}% missing).\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses the raw crime data.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Strip whitespace in string columns\n",
    "    df[df.select_dtypes(include=\"object\").columns] = df.select_dtypes(include=\"object\").apply(\n",
    "        lambda col: col.map(clean_spaces)\n",
    "    )\n",
    "\n",
    "    # Drop columns with excessive NaN\n",
    "    temp_df = df.copy()\n",
    "    for col in list(temp_df.columns):\n",
    "        temp_df = nan_percentage_and_drop(temp_df, col)\n",
    "    df = temp_df\n",
    "\n",
    "    # Age cleanup\n",
    "    df[\"vict_age\"] = pd.to_numeric(df[\"vict_age\"], errors=\"coerce\")\n",
    "    df[\"vict_age\"] = df[\"vict_age\"].apply(\n",
    "        lambda x: np.nan if pd.notna(x) and (x < 10 or x > 100) else x\n",
    "    )\n",
    "\n",
    "    # Map victim demographics\n",
    "    descent_dict = {\n",
    "        \"A\": \"Other Asian\", \"B\": \"Black\", \"C\": \"Chinese\", \"D\": \"Cambodian\",\n",
    "        \"F\": \"Filipino\", \"G\": \"Guamanian\", \"H\": \"Hispanic/Latin/Mexican\",\n",
    "        \"I\": \"American Indian/Alaskan Native\", \"J\": \"Japanese\", \"K\": \"Korean\",\n",
    "        \"L\": \"Laotian\", \"O\": \"Other\", \"P\": \"Pacific Islander\", \"S\": \"Samoan\",\n",
    "        \"U\": \"Hawaiian\", \"V\": \"Vietnamese\", \"W\": \"White\", \"X\": \"Unknown\", \"Z\": \"Asian Indian\"\n",
    "    }\n",
    "    sex_dict = {\"F\": \"Female\", \"M\": \"Male\", \"X\": \"Unknown\"}\n",
    "\n",
    "    df[\"vict_descent\"] = df[\"vict_descent\"].map(descent_dict).fillna(\"Unknown\")\n",
    "    df[\"vict_sex\"] = df[\"vict_sex\"].map(sex_dict).fillna(\"Unknown\")\n",
    "\n",
    "    # Date processing\n",
    "    df = df.copy()\n",
    "    df[\"DATE OCC parsed\"] = pd.to_datetime(df[\"date_occ\"], errors=\"coerce\")\n",
    "    df = df[~df[\"DATE OCC parsed\"].isna()]\n",
    "    df[\"date_occ\"] = df[\"DATE OCC parsed\"].dt.date\n",
    "\n",
    "    df[\"Date Rptd parsed\"] = pd.to_datetime(df[\"date_rptd\"], errors=\"coerce\")\n",
    "    df = df[~df[\"Date Rptd parsed\"].isna()]\n",
    "    df[\"date_rptd\"] = df[\"Date Rptd parsed\"].dt.date\n",
    "\n",
    "    # Drop 2025 data\n",
    "    mask_2025 = (\n",
    "        (pd.to_datetime(df[\"date_occ\"]).dt.year == 2025)\n",
    "        | (pd.to_datetime(df[\"date_rptd\"]).dt.year == 2025)\n",
    "    )\n",
    "    df = df[~mask_2025]\n",
    "\n",
    "    # Time cleanup\n",
    "    df[\"TIME OCC num\"] = pd.to_numeric(df[\"time_occ\"], errors=\"coerce\")\n",
    "    df = df[df[\"TIME OCC num\"] > 99]\n",
    "    df[\"time_occ\"] = df[\"TIME OCC num\"].astype(int).astype(str).str.zfill(4)\n",
    "    df[\"time_occ\"] = df[\"time_occ\"].str[:2] + \":\" + df[\"time_occ\"].str[2:]\n",
    "\n",
    "    # Drop helper columns\n",
    "    df.drop(columns=[\"DATE OCC parsed\", \"Date Rptd parsed\", \"TIME OCC num\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_data(df, filename=\"cleaned_data.csv\"):\n",
    "    \"\"\"\n",
    "    Saves cleaned DataFrame to the processed data folder.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Cleaned DataFrame.\n",
    "        filename (str): Output file name.\n",
    "    \"\"\"\n",
    "    processed_folder = Path.cwd().parent / \"data\" / \"processed\"\n",
    "    processed_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_path = processed_folder / filename\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"DataFrame exported to: {file_path}\")\n",
    "\n",
    "def clean_and_save_data(output_path: Path):\n",
    "    \"\"\"Fetches raw data, cleans it, and saves to output_path\"\"\"\n",
    "    raw_df = fetch_data()\n",
    "    cleaned_df = clean_data(raw_df)\n",
    "    save_data(cleaned_df, output_path)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Run the full pipeline when executed directly\n",
    "    raw_df = fetch_data()\n",
    "    cleaned_df = clean_data(raw_df)\n",
    "    save_data(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1036e2-a9a1-47f8-817a-55229e26c44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
